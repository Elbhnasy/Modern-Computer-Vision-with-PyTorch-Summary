{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for Image Classification\n",
    "\n",
    "- ###### Transfer learning involves leveraging knowledge gained from training a model on a generic dataset, typically consisting of millions of images, and fine-tuning it on a specific dataset of interest. This technique allows the model to adapt its learned features to the characteristics of the new dataset quickly, potentially improving performance and efficiency.\n",
    "- ###### Transfer learning is a technique where knowledge gained from one task is leveraged to solve another similar task.\n",
    "\n",
    "- **Topics are covered in the chapter**:\n",
    "    - Introducing transfer learning\n",
    "    - Understanding VGG16 and ResNet architectures\n",
    "    - Implementing facial key point detection\n",
    "    - Multi-task learning: Implementing age estimation and gender classification\n",
    "    - Introducing the torch_snippets library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer Learning High-Level Flow:**\n",
    "\n",
    "1. **Input Normalization:**\n",
    "   - Normalize input images using the same mean and standard deviation as used during the training of the pre-trained model.\n",
    "\n",
    "2. **Fetch Pre-trained Model:**\n",
    "   - Obtain the architecture of the pre-trained model.\n",
    "   - Fetch the weights learned by the pre-trained model on a large dataset.\n",
    "\n",
    "3. **Truncate Pre-trained Model:**\n",
    "   - Remove the last few layers of the pre-trained model.\n",
    "\n",
    "4. **Connect to New Layers:**\n",
    "   - Connect the truncated pre-trained model to a newly initialized layer (or layers).\n",
    "   - Ensure the output of the last layer matches the number of classes/outputs for prediction.\n",
    "\n",
    "5. **Freeze Pre-trained Weights:**\n",
    "   - Make the weights of the pre-trained model non-trainable (frozen) during backpropagation.\n",
    "   - Train only the weights of the newly initialized layer and those connecting it to the output layer.\n",
    "     - Rationale: Leverage the well-learned features of the pre-trained model for the task at hand.\n",
    "\n",
    "6. **Training:**\n",
    "   - Update the trainable parameters (weights of the new layers) over increasing epochs to fit the model to the specific dataset.\n",
    "   - Gradually fine-tune the model on the smaller dataset, allowing it to adapt to specific features while retaining the knowledge from the pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Understanding VGG16 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### `VGG` stands for `Visual Geometry Group`, which is based out of the University of Oxford, and 16 stands for the number of layers in the model. The VGG16 model is trained to classify objects in the ImageNet competition and stood as the runner-up architecture in 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import the required packages\n",
    "import torchvision\n",
    "from torchvision import models , transforms , datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torchsummary import summary\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 7, 7]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 224, 224]        1,792\n",
      "|    └─ReLU: 2-2                         [-1, 64, 224, 224]        --\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 224, 224]        36,928\n",
      "|    └─ReLU: 2-4                         [-1, 64, 224, 224]        --\n",
      "|    └─MaxPool2d: 2-5                    [-1, 64, 112, 112]        --\n",
      "|    └─Conv2d: 2-6                       [-1, 128, 112, 112]       73,856\n",
      "|    └─ReLU: 2-7                         [-1, 128, 112, 112]       --\n",
      "|    └─Conv2d: 2-8                       [-1, 128, 112, 112]       147,584\n",
      "|    └─ReLU: 2-9                         [-1, 128, 112, 112]       --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 128, 56, 56]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 56, 56]         295,168\n",
      "|    └─ReLU: 2-12                        [-1, 256, 56, 56]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 256, 56, 56]         590,080\n",
      "|    └─ReLU: 2-14                        [-1, 256, 56, 56]         --\n",
      "|    └─Conv2d: 2-15                      [-1, 256, 56, 56]         590,080\n",
      "|    └─ReLU: 2-16                        [-1, 256, 56, 56]         --\n",
      "|    └─MaxPool2d: 2-17                   [-1, 256, 28, 28]         --\n",
      "|    └─Conv2d: 2-18                      [-1, 512, 28, 28]         1,180,160\n",
      "|    └─ReLU: 2-19                        [-1, 512, 28, 28]         --\n",
      "|    └─Conv2d: 2-20                      [-1, 512, 28, 28]         2,359,808\n",
      "|    └─ReLU: 2-21                        [-1, 512, 28, 28]         --\n",
      "|    └─Conv2d: 2-22                      [-1, 512, 28, 28]         2,359,808\n",
      "|    └─ReLU: 2-23                        [-1, 512, 28, 28]         --\n",
      "|    └─MaxPool2d: 2-24                   [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-25                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-26                        [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-27                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-28                        [-1, 512, 14, 14]         --\n",
      "|    └─Conv2d: 2-29                      [-1, 512, 14, 14]         2,359,808\n",
      "|    └─ReLU: 2-30                        [-1, 512, 14, 14]         --\n",
      "|    └─MaxPool2d: 2-31                   [-1, 512, 7, 7]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 512, 7, 7]           --\n",
      "├─Sequential: 1-3                        [-1, 1000]                --\n",
      "|    └─Linear: 2-32                      [-1, 4096]                102,764,544\n",
      "|    └─ReLU: 2-33                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-34                     [-1, 4096]                --\n",
      "|    └─Linear: 2-35                      [-1, 4096]                16,781,312\n",
      "|    └─ReLU: 2-36                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-37                     [-1, 4096]                --\n",
      "|    └─Linear: 2-38                      [-1, 1000]                4,097,000\n",
      "==========================================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 15.61\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 103.43\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 631.80\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 512, 7, 7]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 224, 224]        1,792\n",
       "|    └─ReLU: 2-2                         [-1, 64, 224, 224]        --\n",
       "|    └─Conv2d: 2-3                       [-1, 64, 224, 224]        36,928\n",
       "|    └─ReLU: 2-4                         [-1, 64, 224, 224]        --\n",
       "|    └─MaxPool2d: 2-5                    [-1, 64, 112, 112]        --\n",
       "|    └─Conv2d: 2-6                       [-1, 128, 112, 112]       73,856\n",
       "|    └─ReLU: 2-7                         [-1, 128, 112, 112]       --\n",
       "|    └─Conv2d: 2-8                       [-1, 128, 112, 112]       147,584\n",
       "|    └─ReLU: 2-9                         [-1, 128, 112, 112]       --\n",
       "|    └─MaxPool2d: 2-10                   [-1, 128, 56, 56]         --\n",
       "|    └─Conv2d: 2-11                      [-1, 256, 56, 56]         295,168\n",
       "|    └─ReLU: 2-12                        [-1, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-13                      [-1, 256, 56, 56]         590,080\n",
       "|    └─ReLU: 2-14                        [-1, 256, 56, 56]         --\n",
       "|    └─Conv2d: 2-15                      [-1, 256, 56, 56]         590,080\n",
       "|    └─ReLU: 2-16                        [-1, 256, 56, 56]         --\n",
       "|    └─MaxPool2d: 2-17                   [-1, 256, 28, 28]         --\n",
       "|    └─Conv2d: 2-18                      [-1, 512, 28, 28]         1,180,160\n",
       "|    └─ReLU: 2-19                        [-1, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-20                      [-1, 512, 28, 28]         2,359,808\n",
       "|    └─ReLU: 2-21                        [-1, 512, 28, 28]         --\n",
       "|    └─Conv2d: 2-22                      [-1, 512, 28, 28]         2,359,808\n",
       "|    └─ReLU: 2-23                        [-1, 512, 28, 28]         --\n",
       "|    └─MaxPool2d: 2-24                   [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-25                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-26                        [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-27                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-28                        [-1, 512, 14, 14]         --\n",
       "|    └─Conv2d: 2-29                      [-1, 512, 14, 14]         2,359,808\n",
       "|    └─ReLU: 2-30                        [-1, 512, 14, 14]         --\n",
       "|    └─MaxPool2d: 2-31                   [-1, 512, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [-1, 512, 7, 7]           --\n",
       "├─Sequential: 1-3                        [-1, 1000]                --\n",
       "|    └─Linear: 2-32                      [-1, 4096]                102,764,544\n",
       "|    └─ReLU: 2-33                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-34                     [-1, 4096]                --\n",
       "|    └─Linear: 2-35                      [-1, 4096]                16,781,312\n",
       "|    └─ReLU: 2-36                        [-1, 4096]                --\n",
       "|    └─Dropout: 2-37                     [-1, 4096]                --\n",
       "|    └─Linear: 2-38                      [-1, 1000]                4,097,000\n",
       "==========================================================================================\n",
       "Total params: 138,357,544\n",
       "Trainable params: 138,357,544\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.61\n",
       "==========================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 103.43\n",
       "Params size (MB): 527.79\n",
       "Estimated Total Size (MB): 631.80\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Load the VGG16 model and register the model within the device\n",
    "model = models.vgg16(weights='IMAGENET1K_V1').to(device)\n",
    "\n",
    "# 3. Fetch the summary of the model\n",
    "summary(model,torch.zeros(1,3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 16 layers we mentioned are grouped as follows:\n",
    "\n",
    "    - {1,2},{3,4,5},{6,7},{8,9,10},{11,12},{13,14},{15,16,17},{18,19},{20,21},{22,23,24},{25,26},{27,28},{29,30,31,32},{33,3 4,35},{36 37,38},{39}\n",
    "\n",
    "\n",
    "\n",
    "- `Note` that there are ~138 million parameters (of which ~122 million are the linear layers at the end of the network – 102 + 16 + 4 million parameters) in this network, which comprises 13 layers of convolution and/or pooling, with increasing number of filters, and 3 linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to understand the components of the VGG16 model is by simply printing \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model has three sub-modules: features, avgpool, and classifier.\n",
    "- It's common to freeze features and avgpool during transfer learning.\n",
    "- Remove the classifier module (or some bottom layers).\n",
    "- Replace it with a new classifier for the specific dataset classes.\n",
    "- Adapt the output to predict the desired number of classes (not the original 1,000)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
