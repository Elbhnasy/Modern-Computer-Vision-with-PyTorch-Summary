{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for Image Classification\n",
    "\n",
    "- ###### Transfer learning involves leveraging knowledge gained from training a model on a generic dataset, typically consisting of millions of images, and fine-tuning it on a specific dataset of interest. This technique allows the model to adapt its learned features to the characteristics of the new dataset quickly, potentially improving performance and efficiency.\n",
    "- ###### Transfer learning is a technique where knowledge gained from one task is leveraged to solve another similar task.\n",
    "\n",
    "- **Topics are covered in the chapter**:\n",
    "    - Introducing transfer learning\n",
    "    - Understanding VGG16 and ResNet architectures\n",
    "    - Implementing facial key point detection\n",
    "    - Multi-task learning: Implementing age estimation and gender classification\n",
    "    - Introducing the torch_snippets library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer Learning High-Level Flow:**\n",
    "\n",
    "1. **Input Normalization:**\n",
    "   - Normalize input images using the same mean and standard deviation as used during the training of the pre-trained model.\n",
    "\n",
    "2. **Fetch Pre-trained Model:**\n",
    "   - Obtain the architecture of the pre-trained model.\n",
    "   - Fetch the weights learned by the pre-trained model on a large dataset.\n",
    "\n",
    "3. **Truncate Pre-trained Model:**\n",
    "   - Remove the last few layers of the pre-trained model.\n",
    "\n",
    "4. **Connect to New Layers:**\n",
    "   - Connect the truncated pre-trained model to a newly initialized layer (or layers).\n",
    "   - Ensure the output of the last layer matches the number of classes/outputs for prediction.\n",
    "\n",
    "5. **Freeze Pre-trained Weights:**\n",
    "   - Make the weights of the pre-trained model non-trainable (frozen) during backpropagation.\n",
    "   - Train only the weights of the newly initialized layer and those connecting it to the output layer.\n",
    "     - Rationale: Leverage the well-learned features of the pre-trained model for the task at hand.\n",
    "\n",
    "6. **Training:**\n",
    "   - Update the trainable parameters (weights of the new layers) over increasing epochs to fit the model to the specific dataset.\n",
    "   - Gradually fine-tune the model on the smaller dataset, allowing it to adapt to specific features while retaining the knowledge from the pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Understanding VGG16 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
